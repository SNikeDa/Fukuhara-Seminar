{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fukuhara-Seminar-Week-01: Python Analysis Reviewing Textbook\n",
    "\n",
    "## 0.0: Contents Table\n",
    "- Data Colecting\n",
    "  - データの概要とか、期間や種類とか、選んだ理由ちょいと\n",
    "- Regression & Hypothesis Testing\n",
    "  - CAPMのベータ計算：\n",
    "  - 重回帰分析：\n",
    "- Asuumption\n",
    "  - (Zero mean)\n",
    "  - Homoscedasticy\n",
    "    - breusc-pagan\n",
    "  - No Autocorrelation(DW)\n",
    "  - Exogeneity(dollow from non-stochastic X)...N/A out of scope\n",
    "    - Cov(u, X)=0\n",
    "  - Normality→python guide\n",
    "    - jarque bera\n",
    "  - Linearity\n",
    "    - RESET\n",
    "  - Stability\n",
    "    - cusum\n",
    "- Minimum Variance Portofolio and Market Portofolio\n",
    "  - Portfolio theory\n",
    "- (Copula)\n",
    "\n",
    "\n",
    "## 1.0: Make monthly stock dataset for 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data as web\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "from scipy.optimize import minimize\n",
    "import cvxpy as cp\n",
    "\n",
    "# ターゲットとなる企業のティッカーと企業名のリスト\n",
    "tickers = [\n",
    "    \"1925\", \"1928\", \"2413\", \"2502\", \"2503\", \"2802\", \"2914\", \"3382\", \"3402\", \"3407\", \"4063\", \"4188\", \"4452\", \"4502\", \"4503\", \"4507\", \"4519\", \"4523\", \"4528\", \"4543\", \"4568\", \"4578\", \"4661\", \"4689\", \"4901\", \"4911\", \"5020\", \"5108\", \"5401\", \"5713\", \"5802\", \"6098\", \"6178\", \"6273\", \"6301\", \"6326\", \"6367\", \"6501\", \"6502\", \"6503\", \"6586\", \"6594\", \"6645\", \"6702\", \"6752\", \"6758\", \"6861\", \"6869\", \"6902\", \"6920\", \"6954\", \"6971\", \"6981\", \"7011\", \"7201\", \"7203\", \"7267\", \"7269\", \"7270\", \"7309\", \"7733\", \"7741\", \"7751\", \"7832\", \"7974\", \"8001\", \"8002\", \"8031\", \"8035\", \"8053\", \"8058\", \"8113\", \"8267\", \"8306\", \"8308\", \"8309\", \"8316\", \"8411\", \"8591\", \"8604\", \"8630\", \"8697\", \"8725\", \"8750\", \"8766\", \"8801\", \"8802\", \"8830\", \"9020\", \"9021\", \"9022\", \"9101\", \"9202\", \"9432\", \"9433\", \"9434\", \"9735\", \"9843\", \"9983\", \"9984\", \"TOPIX100\", '1475'\n",
    "]\n",
    "\n",
    "companies = [\n",
    "    '大和ハウス工業','積水ハウス','エムスリー','アサヒグループホールディングス','キリンホールディングス','味の素','日本たばこ産業','セブン＆アイ・ホールディングス','東レ','旭化成','信越化学工業','三菱ケミカルホールディングス','花王','武田薬品工業','アステラス製薬','塩野義製薬','中外製薬','エーザイ','小野薬品工業','テルモ','第一三共','大塚ホールディングス','オリエンタルランド','Ｚホールディングス','富士フイルムホールディングス','資生堂','JXTGホールディングス','ブリヂストン','日本製鉄','住友金属鉱山','住友電気工業','リクルートホールディングス','日本郵政','SMC','小松製作所','クボタ','ダイキン工業','日立製作所','東芝','三菱電機','マキタ','日本電産','オムロン','富士通','パナソニック','ソニー','キーエンス','シスメックス','デンソー','レーザーテック','銘柄名','ファナック','京セラ','村田製作所','三菱重工業','日産自動車','トヨタ自動車','本田技研工業','スズキ','SUBARU','シマノ','オリンパス','HOYA','キヤノン','バンダイナムコホールディングス','任天堂','伊藤忠商事','丸紅','三井物産','東京エレクトロン','住友商事','三菱商事','ユニ・チャーム','イオン','三菱UFJフィナンシャル・グループ','りそなホールディングス','三井住友トラスト・ホールディングス','三井住友フィナンシャルグループ','みずほフィナンシャルグループ','オリックス','野村ホールディングス','SOMPOホールディングス','日本取引所グループ','MS＆ADインシュアランスグループホールディングス','第一生命ホールディングス','東京海上ホールディングス','三井不動産','三菱地所','住友不動産','東日本旅客鉄道','西日本旅客鉄道','東海旅客鉄道','日本郵船','ANAホールディングス','日本電信電話','KDDI','ソフトバンク','セコム','ニトリホールディングス','ファーストリテイリング','ソフトバンクグループ', 'TOPIX100', 'TOPIX'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/0fg_8nv17y5fjj0s_tq9clbh0000gn/T/ipykernel_52960/3766099655.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[ticker] = data[\"Close\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Data fetching and saving completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/0fg_8nv17y5fjj0s_tq9clbh0000gn/T/ipykernel_52960/3766099655.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[ticker] = data[\"Close\"]\n",
      "/var/folders/yb/0fg_8nv17y5fjj0s_tq9clbh0000gn/T/ipykernel_52960/3766099655.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df.reset_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# TOPIX100の銘柄のティッカーシンボルリストへの変換\n",
    "tickers = [tickers + '.T' for tickers in tickers]\n",
    "\n",
    "# 10年前の日付を取得\n",
    "end_date = pd.Timestamp.now()\n",
    "start_date = end_date - pd.DateOffset(years=10)\n",
    "\n",
    "# 結果を格納するDataFrameの初期化\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # データの取得\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, interval=\"1mo\")\n",
    "        \n",
    "        # データの終値を結果のDataFrameに追加\n",
    "        result_df[ticker] = data[\"Close\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}. Error: {e}\")\n",
    "\n",
    "# Dateを1列目に設定\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "# CSVに保存\n",
    "result_df.to_csv(\"topix100_monthly_data.csv\", index=False)\n",
    "\n",
    "print(\"Data fetching and saving completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>1925.T</th>\n",
       "      <th>1928.T</th>\n",
       "      <th>2413.T</th>\n",
       "      <th>2502.T</th>\n",
       "      <th>2503.T</th>\n",
       "      <th>2802.T</th>\n",
       "      <th>2914.T</th>\n",
       "      <th>3382.T</th>\n",
       "      <th>3402.T</th>\n",
       "      <th>...</th>\n",
       "      <th>9202.T</th>\n",
       "      <th>9432.T</th>\n",
       "      <th>9433.T</th>\n",
       "      <th>9434.T</th>\n",
       "      <th>9735.T</th>\n",
       "      <th>9843.T</th>\n",
       "      <th>9983.T</th>\n",
       "      <th>9984.T</th>\n",
       "      <th>TOPIX100.T</th>\n",
       "      <th>1475.T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>668.25</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>2143.333252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6320.0</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>12933.333008</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>658.75</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>2156.666748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6340.0</td>\n",
       "      <td>4985.0</td>\n",
       "      <td>14466.666992</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>756.25</td>\n",
       "      <td>2813.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>4102.0</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>55.610001</td>\n",
       "      <td>1901.666626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5830.0</td>\n",
       "      <td>4985.0</td>\n",
       "      <td>12703.333008</td>\n",
       "      <td>3781.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>846.25</td>\n",
       "      <td>2852.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>57.009998</td>\n",
       "      <td>2067.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5737.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>11683.333008</td>\n",
       "      <td>3834.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>847.00</td>\n",
       "      <td>2889.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>3944.0</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>56.189999</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5946.0</td>\n",
       "      <td>4475.0</td>\n",
       "      <td>12478.333008</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>3792.0</td>\n",
       "      <td>2905.5</td>\n",
       "      <td>3109.00</td>\n",
       "      <td>5574.0</td>\n",
       "      <td>2101.5</td>\n",
       "      <td>5724.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>6205.0</td>\n",
       "      <td>800.400024</td>\n",
       "      <td>...</td>\n",
       "      <td>3426.0</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>4450.000000</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>9739.0</td>\n",
       "      <td>16105.0</td>\n",
       "      <td>36720.000000</td>\n",
       "      <td>6773.0</td>\n",
       "      <td>1539.900024</td>\n",
       "      <td>2389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>3862.0</td>\n",
       "      <td>2899.0</td>\n",
       "      <td>3263.00</td>\n",
       "      <td>5595.0</td>\n",
       "      <td>2102.5</td>\n",
       "      <td>5537.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>5893.0</td>\n",
       "      <td>795.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>3406.0</td>\n",
       "      <td>162.899994</td>\n",
       "      <td>4187.000000</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>9533.0</td>\n",
       "      <td>17455.0</td>\n",
       "      <td>35560.000000</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>1553.890015</td>\n",
       "      <td>2401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>2970.5</td>\n",
       "      <td>2903.50</td>\n",
       "      <td>5676.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>6173.0</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>5981.0</td>\n",
       "      <td>786.099976</td>\n",
       "      <td>...</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>168.300003</td>\n",
       "      <td>4325.000000</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>10195.0</td>\n",
       "      <td>16620.0</td>\n",
       "      <td>33480.000000</td>\n",
       "      <td>6545.0</td>\n",
       "      <td>1550.140015</td>\n",
       "      <td>2384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>2716.00</td>\n",
       "      <td>5590.0</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>5764.0</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>5855.0</td>\n",
       "      <td>778.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3133.0</td>\n",
       "      <td>176.600006</td>\n",
       "      <td>4577.000000</td>\n",
       "      <td>1690.5</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>16710.0</td>\n",
       "      <td>32590.000000</td>\n",
       "      <td>6335.0</td>\n",
       "      <td>1550.079956</td>\n",
       "      <td>2401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>2842.0</td>\n",
       "      <td>2663.00</td>\n",
       "      <td>5492.0</td>\n",
       "      <td>2092.5</td>\n",
       "      <td>5918.0</td>\n",
       "      <td>3307.0</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>736.200012</td>\n",
       "      <td>...</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>4513.000000</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>10115.0</td>\n",
       "      <td>15520.0</td>\n",
       "      <td>31490.000000</td>\n",
       "      <td>6044.0</td>\n",
       "      <td>1482.430054</td>\n",
       "      <td>2342.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  1925.T  1928.T   2413.T  2502.T  2503.T  2802.T  2914.T  \\\n",
       "0    2013-11-01  1990.0  1413.0   668.25  2804.0  1578.0  1460.0  3460.0   \n",
       "1    2013-12-01  2035.0  1470.0   658.75  2964.0  1513.0  1522.0  3420.0   \n",
       "2    2014-01-01  1964.0  1434.0   756.25  2813.0  1406.0  1454.0  3197.0   \n",
       "3    2014-02-01  1846.0  1274.0   846.25  2852.0  1385.0  1577.0  3232.0   \n",
       "4    2014-03-01  1751.0  1281.0   847.00  2889.0  1430.0  1475.0  3240.0   \n",
       "..          ...     ...     ...      ...     ...     ...     ...     ...   \n",
       "115  2023-06-01  3792.0  2905.5  3109.00  5574.0  2101.5  5724.0  3153.0   \n",
       "116  2023-07-01  3862.0  2899.0  3263.00  5595.0  2102.5  5537.0  3153.0   \n",
       "117  2023-08-01  4048.0  2970.5  2903.50  5676.0  2046.0  6173.0  3191.0   \n",
       "118  2023-09-01  4015.0  2977.0  2716.00  5590.0  2093.0  5764.0  3440.0   \n",
       "119  2023-10-01  4015.0  2842.0  2663.00  5492.0  2092.5  5918.0  3307.0   \n",
       "\n",
       "     3382.T      3402.T  ...  9202.T      9432.T       9433.T  9434.T  \\\n",
       "0    3770.0  724.000000  ...  2070.0   51.400002  2143.333252     NaN   \n",
       "1    4180.0  728.000000  ...  2100.0   56.599998  2156.666748     NaN   \n",
       "2    4102.0  677.000000  ...  2180.0   55.610001  1901.666626     NaN   \n",
       "3    3813.0  701.000000  ...  2270.0   57.009998  2067.000000     NaN   \n",
       "4    3944.0  682.000000  ...  2230.0   56.189999  1992.000000     NaN   \n",
       "..      ...         ...  ...     ...         ...          ...     ...   \n",
       "115  6205.0  800.400024  ...  3426.0  170.500000  4450.000000  1540.0   \n",
       "116  5893.0  795.200012  ...  3406.0  162.899994  4187.000000  1578.0   \n",
       "117  5981.0  786.099976  ...  3290.0  168.300003  4325.000000  1670.0   \n",
       "118  5855.0  778.000000  ...  3133.0  176.600006  4577.000000  1690.5   \n",
       "119  5793.0  736.200012  ...  3086.0  174.500000  4513.000000  1681.0   \n",
       "\n",
       "      9735.T   9843.T        9983.T  9984.T   TOPIX100.T  1475.T  \n",
       "0     6320.0   4745.0  12933.333008  4145.0          NaN     NaN  \n",
       "1     6340.0   4985.0  14466.666992  4600.0          NaN     NaN  \n",
       "2     5830.0   4985.0  12703.333008  3781.5          NaN     NaN  \n",
       "3     5737.0   4600.0  11683.333008  3834.0          NaN     NaN  \n",
       "4     5946.0   4475.0  12478.333008  3900.0          NaN     NaN  \n",
       "..       ...      ...           ...     ...          ...     ...  \n",
       "115   9739.0  16105.0  36720.000000  6773.0  1539.900024  2389.0  \n",
       "116   9533.0  17455.0  35560.000000  7242.0  1553.890015  2401.0  \n",
       "117  10195.0  16620.0  33480.000000  6545.0  1550.140015  2384.0  \n",
       "118  10140.0  16710.0  32590.000000  6335.0  1550.079956  2401.0  \n",
       "119  10115.0  15520.0  31490.000000  6044.0  1482.430054  2342.0  \n",
       "\n",
       "[120 rows x 103 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./topix100_monthly_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各銘柄のデータを数値に変換\n",
    "for column in df.columns:\n",
    "    if column != 'Date':  # Date列はスキップ\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "# 日次収益率を計算する関数\n",
    "def compute_daily_return(price_column):\n",
    "    return price_column.pct_change().fillna(0)\n",
    "\n",
    "# 各銘柄の日次収益率を計算\n",
    "return_columns = []\n",
    "for column in df.columns:\n",
    "    if column != 'Date':  # Date列はスキップ\n",
    "        return_col_name = f'Return_{column}'\n",
    "        df[return_col_name] = compute_daily_return(df[column])\n",
    "        return_columns.append(return_col_name)\n",
    "\n",
    "# 100銘柄全体の平均収益率を計算\n",
    "df['TOPIX100_return'] = df[return_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1276.000000\n",
       "1      1284.000000\n",
       "2      1184.400024\n",
       "3      1167.800049\n",
       "4      1165.199951\n",
       "          ...     \n",
       "115    2308.500000\n",
       "116    2386.000000\n",
       "117    2515.000000\n",
       "118    2677.500000\n",
       "119    2576.500000\n",
       "Name: 7203.T, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['7203.T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>7203.T</td>      <th>  R-squared:         </th> <td>   0.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   127.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>3.55e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:00:23</td>     <th>  Log-Likelihood:    </th> <td> -283.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    43</td>      <th>  AIC:               </th> <td>   570.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>   574.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td> -878.2455</td> <td>  246.835</td> <td>   -3.558</td> <td> 0.001</td> <td>-1376.738</td> <td> -379.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1475.T</th> <td>    1.4101</td> <td>    0.125</td> <td>   11.306</td> <td> 0.000</td> <td>    1.158</td> <td>    1.662</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.439</td> <th>  Durbin-Watson:     </th> <td>   0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.487</td> <th>  Jarque-Bera (JB):  </th> <td>   1.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.278</td> <th>  Prob(JB):          </th> <td>   0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.356</td> <th>  Cond. No.          </th> <td>1.78e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.78e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 7203.T   R-squared:                       0.757\n",
       "Model:                            OLS   Adj. R-squared:                  0.751\n",
       "Method:                 Least Squares   F-statistic:                     127.8\n",
       "Date:                Fri, 06 Oct 2023   Prob (F-statistic):           3.55e-14\n",
       "Time:                        13:00:23   Log-Likelihood:                -283.27\n",
       "No. Observations:                  43   AIC:                             570.5\n",
       "Df Residuals:                      41   BIC:                             574.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -878.2455    246.835     -3.558      0.001   -1376.738    -379.753\n",
       "1475.T         1.4101      0.125     11.306      0.000       1.158       1.662\n",
       "==============================================================================\n",
       "Omnibus:                        1.439   Durbin-Watson:                   0.283\n",
       "Prob(Omnibus):                  0.487   Jarque-Bera (JB):                1.297\n",
       "Skew:                           0.278   Prob(JB):                        0.523\n",
       "Kurtosis:                       2.356   Cond. No.                     1.78e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.78e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "Rf = 0.008 #日本10年国債\n",
    "\n",
    "TOYOTA = LinearRegression()\n",
    "X = df[\"1475.T\"] - Rf\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"7203.T\"] - Rf #print(X)\n",
    "#print(y)\n",
    "TOYOTA = sm.OLS(y, X).fit()\n",
    "TOYOTA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>7974.T</td>      <th>  R-squared:         </th> <td>   0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>0.000345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:00:29</td>     <th>  Log-Likelihood:    </th> <td> -327.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    43</td>      <th>  AIC:               </th> <td>   658.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>   661.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td> 3109.6070</td> <td>  682.642</td> <td>    4.555</td> <td> 0.000</td> <td> 1730.983</td> <td> 4488.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1475.T</th> <td>    1.3468</td> <td>    0.345</td> <td>    3.905</td> <td> 0.000</td> <td>    0.650</td> <td>    2.043</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.698</td> <th>  Durbin-Watson:     </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.705</td> <th>  Jarque-Bera (JB):  </th> <td>   0.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.008</td> <th>  Prob(JB):          </th> <td>   0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.367</td> <th>  Cond. No.          </th> <td>1.78e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.78e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 7974.T   R-squared:                       0.271\n",
       "Model:                            OLS   Adj. R-squared:                  0.253\n",
       "Method:                 Least Squares   F-statistic:                     15.25\n",
       "Date:                Fri, 06 Oct 2023   Prob (F-statistic):           0.000345\n",
       "Time:                        13:00:29   Log-Likelihood:                -327.01\n",
       "No. Observations:                  43   AIC:                             658.0\n",
       "Df Residuals:                      41   BIC:                             661.5\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       3109.6070    682.642      4.555      0.000    1730.983    4488.231\n",
       "1475.T         1.3468      0.345      3.905      0.000       0.650       2.043\n",
       "==============================================================================\n",
       "Omnibus:                        0.698   Durbin-Watson:                   0.483\n",
       "Prob(Omnibus):                  0.705   Jarque-Bera (JB):                0.718\n",
       "Skew:                           0.008   Prob(JB):                        0.698\n",
       "Kurtosis:                       2.367   Cond. No.                     1.78e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.78e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "Rf = 0.008 #日本10年国債\n",
    "\n",
    "NINTENDO = LinearRegression()\n",
    "X = df[\"1475.T\"] - Rf\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"7974.T\"] - Rf #print(X)\n",
    "#print(y)\n",
    "NINTENDO = sm.OLS(y, X).fit()\n",
    "NINTENDO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>4911.T</td>      <th>  R-squared:         </th> <td>   0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.7074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.405</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:00:30</td>     <th>  Log-Likelihood:    </th> <td> -349.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    43</td>      <th>  AIC:               </th> <td>   702.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>   706.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td> 7417.7663</td> <td> 1147.033</td> <td>    6.467</td> <td> 0.000</td> <td> 5101.286</td> <td> 9734.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1475.T</th> <td>   -0.4875</td> <td>    0.580</td> <td>   -0.841</td> <td> 0.405</td> <td>   -1.658</td> <td>    0.683</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.898</td> <th>  Durbin-Watson:     </th> <td>   0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.387</td> <th>  Jarque-Bera (JB):  </th> <td>   1.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.289</td> <th>  Prob(JB):          </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.282</td> <th>  Cond. No.          </th> <td>1.78e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.78e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 4911.T   R-squared:                       0.017\n",
       "Model:                            OLS   Adj. R-squared:                 -0.007\n",
       "Method:                 Least Squares   F-statistic:                    0.7074\n",
       "Date:                Fri, 06 Oct 2023   Prob (F-statistic):              0.405\n",
       "Time:                        13:00:30   Log-Likelihood:                -349.33\n",
       "No. Observations:                  43   AIC:                             702.7\n",
       "Df Residuals:                      41   BIC:                             706.2\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       7417.7663   1147.033      6.467      0.000    5101.286    9734.246\n",
       "1475.T        -0.4875      0.580     -0.841      0.405      -1.658       0.683\n",
       "==============================================================================\n",
       "Omnibus:                        1.898   Durbin-Watson:                   0.374\n",
       "Prob(Omnibus):                  0.387   Jarque-Bera (JB):                1.523\n",
       "Skew:                           0.289   Prob(JB):                        0.467\n",
       "Kurtosis:                       2.282   Cond. No.                     1.78e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.78e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "Rf = 0.008 #日本10年国債\n",
    "\n",
    "SISEIDO = LinearRegression()\n",
    "X = df[\"1475.T\"] - Rf\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"4911.T\"] - Rf #print(X)\n",
    "#print(y)\n",
    "SISEIDO = sm.OLS(y, X).fit()\n",
    "SISEIDO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb セル 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m FOOD \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m df[[\u001b[39m\"\u001b[39;49m\u001b[39m2802.T\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m2503.T\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2502.T\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39madd_constant(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39m1475.T\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "FOOD = LinearRegression()\n",
    "X = df[[\"2802.T\", \"2503.T\", '2502.T']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['1475.T']\n",
    "#print(X)\n",
    "#print(y)\n",
    "MLR = sm.OLS(y, X).fit()\n",
    "MLR.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOYOTA\n",
      "Significance Level: 0.01 - Reject the null hypothesis. Coefficient (1.4101) is greater than 1.\n",
      "Significance Level: 0.05 - Reject the null hypothesis. Coefficient (1.4101) is greater than 1.\n",
      "Significance Level: 0.10 - Reject the null hypothesis. Coefficient (1.4101) is greater than 1.\n",
      "Coefficient: 1.4101\n",
      "t-statistic: 3.2879\n",
      "p-value: 0.0010\n",
      "\n",
      "\n",
      "NINTENDO\n",
      "Significance Level: 0.01 - Fail to reject the null hypothesis. Coefficient (1.3468) is not greater than 1.\n",
      "Significance Level: 0.05 - Fail to reject the null hypothesis. Coefficient (1.3468) is not greater than 1.\n",
      "Significance Level: 0.10 - Fail to reject the null hypothesis. Coefficient (1.3468) is not greater than 1.\n",
      "Coefficient: 1.3468\n",
      "t-statistic: 1.0056\n",
      "p-value: 0.1603\n",
      "\n",
      "\n",
      "SISEIDO\n",
      "Significance Level: 0.01 - Reject the null hypothesis. Coefficient (-0.4875) is greater than 1.\n",
      "Significance Level: 0.05 - Reject the null hypothesis. Coefficient (-0.4875) is greater than 1.\n",
      "Significance Level: 0.10 - Reject the null hypothesis. Coefficient (-0.4875) is greater than 1.\n",
      "Coefficient: -0.4875\n",
      "t-statistic: -2.5665\n",
      "p-value: 0.0070\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "for model in [TOYOTA, NINTENDO, SISEIDO]:\n",
    "    coefficient_to_test = model.params[1]\n",
    "    \n",
    "    # Define the null hypothesis (H0) and alternative hypothesis (H1\n",
    "    null_hypothesis = 1 # Coefficient = 1 under the null hypothesis # Compute the standard error of the coefficient estimate\n",
    "    std_err = model.bse[1]\n",
    "    \n",
    "    # Compute the t-statistic\n",
    "    t_statistic = (coefficient_to_test - null_hypothesis) / std_err \n",
    "    \n",
    "    # Calculate the degrees of freedom\n",
    "    df = model.df_resid\n",
    "    \n",
    "    # Calculate the p-value for a one-sided t-test\n",
    "    p_value = 1 - stats.t.cdf(np.abs(t_statistic), df)\n",
    "    \n",
    "    # Check if the p-value is less than your significance level (e.g\n",
    "    alpha_levels = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    # Correctly determine the model's name\n",
    "    if model is TOYOTA:\n",
    "        print(\"TOYOTA\")\n",
    "    elif model is NINTENDO:\n",
    "        print(\"NINTENDO\")\n",
    "    elif model is SISEIDO:\n",
    "        print(\"SISEIDO\")\n",
    "    \n",
    "    # Print the coefficient and test results for different significance levels\n",
    "    for alpha in alpha_levels:\n",
    "        if p_value < alpha:\n",
    "            print(f\"Significance Level: {alpha:.2f} - Reject the null hypothesis. Coefficient ({coefficient_to_test:.4f}) is greater than 1.\")\n",
    "        else:\n",
    "            print(f\"Significance Level: {alpha:.2f} - Fail to reject the null hypothesis. Coefficient ({coefficient_to_test:.4f}) is not greater than 1.\")\n",
    "    \n",
    "    # Display the t-statistic and p-value\n",
    "    print(f\"Coefficient: {coefficient_to_test:.4f}\")\n",
    "    print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb セル 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/klynoaguilar/Desktop/01_school/Fukuhara-Seminar/23_10_06_week-01/24_fall_week01.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39m7203.T\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "df['7203.T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "銘柄名: 7203.T\n",
      "White-test p-value: 0.0023\n",
      "The residuals do not have heteroscedasticity.\n",
      "------------------------------\n",
      "銘柄名: 7974.T\n",
      "White-test p-value: 0.0018\n",
      "The residuals do not have heteroscedasticity.\n",
      "------------------------------\n",
      "銘柄名: 4911.T\n",
      "White-test p-value: 0.0017\n",
      "The residuals do not have heteroscedasticity.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "# 対象とする銘柄のリスト\n",
    "tickers = ['7203.T', '7974.T', '4911.T']  # ここに実際の銘柄コードを入力してください\n",
    "\n",
    "for ticker in tickers:\n",
    "    # 株価データ\n",
    "    y = df[ticker]\n",
    "    \n",
    "    # 時間（または日数）を独立変数として設定\n",
    "    X = np.array(range(len(y)))\n",
    "    \n",
    "    # 線形モデルの構築\n",
    "    X = sm.add_constant(X)  # 定数項（切片）を追加\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    print(f\"銘柄名: {ticker}\")\n",
    "    \n",
    "    # White-test\n",
    "    _, pval, _, f_pval = het_white(model.resid, model.model.exog)\n",
    "    print(f\"White-test p-value: {pval:.4f}\")\n",
    "\n",
    "    if pval < 0.0001:\n",
    "        print(\"The residuals have heteroscedasticity.\")\n",
    "    else:\n",
    "        print(\"The residuals do not have heteroscedasticity.\")\n",
    "    \n",
    "    print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "銘柄名: 7203.T\n",
      "Durbin-Watson statistic: 0.1508\n",
      "There might be positive autocorrelation.\n",
      "------------------------------\n",
      "銘柄名: 7974.T\n",
      "Durbin-Watson statistic: 0.2657\n",
      "There might be positive autocorrelation.\n",
      "------------------------------\n",
      "銘柄名: 4911.T\n",
      "Durbin-Watson statistic: 0.0938\n",
      "There might be positive autocorrelation.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "tickers = ['7203.T', '7974.T', '4911.T']   # ここに実際の銘柄コードを入力してください\n",
    "\n",
    "for ticker in tickers:\n",
    "    # 株価データ\n",
    "    y = df[ticker]\n",
    "    \n",
    "    # 時間（または日数）を独立変数として設定\n",
    "    X = np.array(range(len(y)))\n",
    "    \n",
    "    # 線形モデルの構築\n",
    "    X = sm.add_constant(X)  # 定数項（切片）を追加\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    print(f\"銘柄名: {ticker}\")\n",
    "    \n",
    "    # Durbin-Watson統計量\n",
    "    dw_stat = sm.stats.durbin_watson(model.resid)\n",
    "    print(f\"Durbin-Watson statistic: {dw_stat:.4f}\")\n",
    "\n",
    "    if dw_stat < 1.5:\n",
    "        print(\"There might be positive autocorrelation.\")\n",
    "    elif dw_stat > 2.5:\n",
    "        print(\"There might be negative autocorrelation.\")\n",
    "    else:\n",
    "        print(\"No significant autocorrelation detected.\")\n",
    "    \n",
    "    print(\"------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fukuhara_Seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
