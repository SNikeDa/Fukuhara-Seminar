{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: 下準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1: ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "from scipy.optimize import minimize\n",
    "import cvxpy as cp\n",
    "import pytz\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import statsmodels.tsa.api as smt\n",
    "from copy import deepcopy\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import arma_order_select_ic\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import statsmodels.tools.eval_measures\n",
    "import scipy \n",
    "from scipy import stats\n",
    "import time\n",
    "from attrdict import AttrDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2: データのインポート/作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1925.T': None, '1928.T': None, '2413.T': None, '2502.T': None, '2503.T': None, '2802.T': None, '2914.T': None, '3382.T': None, '3402.T': None, '3407.T': None, '4063.T': None, '4188.T': None, '4452.T': None, '4502.T': None, '4503.T': None, '4507.T': None, '4519.T': None, '4523.T': None, '4528.T': None, '4543.T': None, '4568.T': None, '4578.T': None, '4661.T': None, '4689.T': None, '4901.T': None, '4911.T': None, '5020.T': None, '5108.T': None, '5401.T': None, '5713.T': None, '5802.T': None, '6098.T': None, '6178.T': None, '6273.T': None, '6301.T': None, '6326.T': None, '6367.T': None, '6501.T': None, '6502.T': None, '6503.T': None, '6586.T': None, '6594.T': None, '6645.T': None, '6702.T': None, '6752.T': None, '6758.T': None, '6861.T': None, '6869.T': None, '6902.T': None, '6920.T': None, '6954.T': None, '6971.T': None, '6981.T': None, '7011.T': None, '7201.T': None, '7203.T': None, '7267.T': None, '7269.T': None, '7270.T': None, '7309.T': None, '7733.T': None, '7741.T': None, '7751.T': None, '7832.T': None, '7974.T': None, '8001.T': None, '8002.T': None, '8031.T': None, '8035.T': None, '8053.T': None, '8058.T': None, '8113.T': None, '8267.T': None, '8306.T': None, '8308.T': None, '8309.T': None, '8316.T': None, '8411.T': None, '8591.T': None, '8604.T': None, '8630.T': None, '8697.T': None, '8725.T': None, '8750.T': None, '8766.T': None, '8801.T': None, '8802.T': None, '8830.T': None, '9020.T': None, '9021.T': None, '9022.T': None, '9101.T': None, '9202.T': None, '9432.T': None, '9433.T': None, '9434.T': None, '9735.T': None, '9843.T': None, '9983.T': None, '9984.T': None, 'TOPIX100.T': None, '1475.T': None}\n"
     ]
    }
   ],
   "source": [
    "def convert_to_tickers_format(raw_tickers):\n",
    "    ''' Raw tickersを対象フォーマットに変換 '''\n",
    "    return [ticker + '.T' for ticker in raw_tickers]\n",
    "\n",
    "\n",
    "def get_ticker_to_name_mapping(tickers):\n",
    "    ''' Tickerの企業名の辞書を作成 '''\n",
    "    ticker_to_name = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            company_info = yf.Ticker(ticker)\n",
    "            company_name = company_info.info[\"shortName\"]\n",
    "            ticker_to_name[ticker] = company_name\n",
    "        except:\n",
    "            ticker_to_name[ticker] = None\n",
    "    return ticker_to_name\n",
    "\n",
    "\n",
    "all_raw_tickers = [\n",
    "    \"1925\", \"1928\", \"2413\", \"2502\", \"2503\", \"2802\", \"2914\", \"3382\", \"3402\", \"3407\", \"4063\", \"4188\", \"4452\", \"4502\", \"4503\", \"4507\", \"4519\", \"4523\", \"4528\", \"4543\", \"4568\", \"4578\", \"4661\", \"4689\", \"4901\", \"4911\", \"5020\", \"5108\", \"5401\", \"5713\", \"5802\", \"6098\", \"6178\", \"6273\", \"6301\", \"6326\", \"6367\", \"6501\", \"6502\", \"6503\", \"6586\", \"6594\", \"6645\", \"6702\", \"6752\", \"6758\", \"6861\", \"6869\", \"6902\", \"6920\", \"6954\", \"6971\", \"6981\", \"7011\", \"7201\", \"7203\", \"7267\", \"7269\", \"7270\", \"7309\", \"7733\", \"7741\", \"7751\", \"7832\", \"7974\", \"8001\", \"8002\", \"8031\", \"8035\", \"8053\", \"8058\", \"8113\", \"8267\", \"8306\", \"8308\", \"8309\", \"8316\", \"8411\", \"8591\", \"8604\", \"8630\", \"8697\", \"8725\", \"8750\", \"8766\", \"8801\", \"8802\", \"8830\", \"9020\", \"9021\", \"9022\", \"9101\", \"9202\", \"9432\", \"9433\", \"9434\", \"9735\", \"9843\", \"9983\", \"9984\", \"TOPIX100\", '1475'\n",
    "]\n",
    "\n",
    "all_tickers = convert_to_tickers_format(all_raw_tickers)\n",
    "dict_ticker_to_name = get_ticker_to_name_mapping(all_tickers)\n",
    "print(dict_ticker_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定数の設定'''\n",
    "YEARS_BACK = 10  # 取得するデータの期間を10年とする\n",
    "INTERVALS = [\"1mo\", \"1wk\", \"1d\"]  # 取得するデータの間隔\n",
    "\n",
    "def fetch_and_save_data(tickers, interval):\n",
    "    ''' 指定されたティッカーと間隔に基づいてデータを取得し、CSVとして保存する '''\n",
    "    result_df = pd.DataFrame()\n",
    "    end_date = pd.Timestamp.now()\n",
    "    start_date = end_date - pd.DateOffset(years=YEARS_BACK)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "            result_df[ticker] = data[\"Close\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}. Error: {e}\")\n",
    "\n",
    "    result_df.reset_index(inplace=True)\n",
    "    csv_filename = f\"/Users/klynoaguilar/Desktop/01_school/Zemi/23_10_27_weeek-03/topix100_{interval}_data.csv\"\n",
    "    result_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Data fetching and saving for {interval} completed!\")\n",
    "\n",
    "def main_making_data():\n",
    "    for interval in INTERVALS:\n",
    "        fetch_and_save_data(all_tickers, interval)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_making_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mo = pd.read_csv('./topix100_1mo_data.csv')\n",
    "df_we = pd.read_csv('./topix100_1wk_data.csv')\n",
    "df_da = pd.read_csv('./topix100_1d_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA = {\n",
    "  'tickers': {\n",
    "    'tc_all_raw': all_raw_tickers,\n",
    "    'tc_all_formatted': all_tickers,\n",
    "    'tc_dict_ticker_to_company_name': dict_ticker_to_name\n",
    "  },\n",
    "  'dataframe': {\n",
    "    'df_mo': df_mo,\n",
    "    'df_we': df_we,\n",
    "    'df_da': df_da\n",
    "  }\n",
    "}\n",
    "\n",
    "# 上で定義したID辞書をAttrDictに渡す\n",
    "ALL_DATA = AttrDict(ALL_DATA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4: データの整形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: データ分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mo had 0 rows with NaN values removed.\n",
      "df_we had 0 rows with NaN values removed.\n",
      "df_da had 0 rows with NaN values removed.\n"
     ]
    }
   ],
   "source": [
    "# 各DataFrameでNaNを含む行を排除する関数\n",
    "def remove_na_rows(df):\n",
    "    before_rows = len(df)\n",
    "    df.dropna(inplace=True)\n",
    "    after_rows = len(df)\n",
    "    removed_rows = before_rows - after_rows\n",
    "    return removed_rows\n",
    "\n",
    "# ALL_DATA内の各DataFrameに関してNaNを含む行を排除する\n",
    "for key in ALL_DATA.dataframe:\n",
    "    removed_rows = remove_na_rows(ALL_DATA.dataframe[key])\n",
    "    print(f\"{key} had {removed_rows} rows with NaN values removed.\")\n",
    "\n",
    "# この後、ALL_DATA.dataframe['df-monthly']などでアクセスすると、NaNを含む行が排除されたDataFrameが返されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3: 関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fukuhara_Seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
